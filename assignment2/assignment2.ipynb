{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF240 - Apprentissage et deep learning\n",
    "\n",
    "## Assignment 2: CNNs for denoising \n",
    "\n",
    "By Aur√©lie Bugeau\n",
    "Credits Charles Deledalle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment,\n",
    "we are going to consider a specific regression problem: image denoising.\n",
    "We will be using deep Convolutional Neural Networks (CNNs) with PyTorch,\n",
    "investigate DnCNN\n",
    "\n",
    "We will be using a subsamples of images from the \"Berkeley Segmentation Dataset and Benchmark\" that can be found on Moodle.\n",
    "_Note: if you wish to obtain better results and experiment further, you can download the whole dataset here. \n",
    "that are downloadable here \\url{https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html#bsds500}_\n",
    "\n",
    "This directory contains two sub-directories: `train` and `test`,\n",
    "which consist of 30 and 10 images, respectively, of either size $321 \\times 481$\n",
    "or $481 \\times 321$.\n",
    "While thousand to millions of images were required\n",
    "for image classification, we can use a much smaller training set\n",
    "for image denoising. This is because denoising each pixel of an image can\n",
    "be seen as one regression problem. Hence, our training is in fact composed\n",
    "of $30 \\times 321 \\times 481 \\approx 31$ million samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_RECOMMENDATION: For this assignment, you may need to run your codes on GPU (either colaboratory or your laptop)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "#import nntools as nt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Creating noisy images of BSDS dataset with DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use deep convolutional neural networks to learn the mapping $x_i \\to y_i$\n",
    "where $x_i$ are noisy images (our data/observations) and $y_i$ are clean images\n",
    "(our labels/ground-truth).\n",
    "\n",
    "We will consider the images of the BSDS dataset as our clean/ground-truth images: $y_i$.\n",
    "For each of them, we will generate noisy versions by adding white Gaussian noise:\n",
    "$x_i = y_i + w_i$ where $w_i$ is an image where each pixel is an independent realization\n",
    "of a zero-mean Gaussian distribution with standard deviation $\\sigma=30$.\n",
    "Since images have different sizes, we will consider random crops of\n",
    "size of $180 \\times 180$.\n",
    "\n",
    "\n",
    "### Question1 \n",
    "Define the directory to store noisy images and explain the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7de286b19cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Dataset class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNoisyBSDSDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the directory to store noisy  images\n",
    "dataset_root_dir = ''#!COMPLETE path to image directory \n",
    "print('Data dir: %s' % dataset_root_dir)\n",
    "\n",
    "#Dataset class\n",
    "class NoisyBSDSDataset(td.Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, mode='train', image_size=(180, 180), sigma=30):\n",
    "        super(NoisyBSDSDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "        self.sigma = sigma\n",
    "        self.images_dir = os.path.join(root_dir, mode)\n",
    "        self.files = sorted(os.listdir(self.images_dir))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"NoisyBSDSDataset(mode={}, image_size={}, sigma={})\". \\\n",
    "            format(self.mode, self.image_size, self.sigma)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.files[idx])\n",
    "        clean = Image.open(img_path).convert('RGB')\n",
    "        i = np.random.randint(clean.size[0] - self.image_size[0])\n",
    "        j = np.random.randint(clean.size[1] - self.image_size[1])\n",
    "        clean = clean.crop([i, j, i + self.image_size[0], j + self.image_size[1]])\n",
    "        transform = tv.transforms.Compose([\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        clean = transform(clean)\n",
    "        noisy = clean + 2 / 255 * self.sigma * torch.randn(clean.shape)\n",
    "        return noisy, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization function\n",
    "def myimshow(image, ax=plt):\n",
    "    image = image.detach().to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image = (image + 1) / 2\n",
    "    image[image < 0] = 0\n",
    "    image[image > 1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build train and test sets\n",
    "train_set = NoisyBSDSDataset(dataset_root_dir, mode='train')\n",
    "test_set = NoisyBSDSDataset(dataset_root_dir, mode='test', image_size=(320, 320))\n",
    "val_set = NoisyBSDSDataset(dataset_root_dir, mode='val', image_size=(320, 320))\n",
    "print(train_set)\n",
    "print(test_set)\n",
    "print(val_set)\n",
    "\n",
    "noisy, clean = test_set[1]\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "myimshow(clean, ax=axes[0])\n",
    "axes[0].set_title('Clean image')\n",
    "myimshow(noisy, ax=axes[1])\n",
    "axes[1].set_title('Noisy image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 DnCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our code more versatile, easy to read and save precious coding time, the architecture is going to inherit from the abstract class `NeuralNetwork` of the `nntools` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nntools as nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main concept introduced in 'nntools'\n",
    "is the abstract class 'NeuralNetwork'.\n",
    "This class describes the general architecture and functionalities that\n",
    "a neural network object is expected to have.\n",
    "In particular it has two methods `forward`\n",
    "and`criterion` used respectively to make a forward pass in the network\n",
    "and compute the loss.\n",
    "Open `nntools.py` to inspect its code.\n",
    "As you can observe these methods are tagged as\n",
    "_abstract_ and as a result the class is said to be abstract.\n",
    "\n",
    "An abstract class does not implement all of its methods and cannot\n",
    "be instantiated.\n",
    "This is because the implementation of `forward` and `criterion` will\n",
    "depend on the specific type and architecture of neural networks we\n",
    "will be considering. The implementation of these two methods will be done\n",
    "in sub-classes following the principle of inheritance.\n",
    "\n",
    "For instance, we can define the subclass `NNRegression`\n",
    "that inherits from `NeuralNetwork`. \n",
    "\n",
    "### Question 2\n",
    "Implement the method\n",
    "`criterion` as being the MSEloss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNRegression(nt.NeuralNetwork):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NNRegression, self).__init__()\n",
    "        self.regression_loss = #!COMPLETE\n",
    "\n",
    "    def criterion(self, y, d):\n",
    "        return self.regression_loss(y, d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to `NeuralNetwork`, this class is more specific\n",
    "as it considers only neural networks that will produce one-hot codes\n",
    "and that are then classifiers. Nevertheless, this class is still abstract\n",
    "as it does not implement the method `forward`. Indeed, the method `forward`\n",
    "depends on the specific architecture of the classification network we will be considering. For denoising we will focus on DnCNN, which has the following architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DnCNN](./dncnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 3\n",
    "Interpret and complete the following code implementing DnCNN. Refer to PyTorch's documentation for detailed explanations about `nn.ModuleList` and `nn.BatchNorm2d`. Note that in order to preserve the spatial feature dimensions between each successive layer of the network, we will have to use zero-padding by a suitable number of pixels that you have to determine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(NNRegression):\n",
    "\n",
    "    def __init__(self, D, C=64, apply_init=True):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.D = D\n",
    "        self.conv = nn.ModuleList()\n",
    "        #!COMPLETE to append every convolutional layers\n",
    "\n",
    "        self.bn = nn.ModuleList()\n",
    "        for k in range(D):\n",
    "            self.bn.append(nn.BatchNorm2d(C))\n",
    "\n",
    "    def forward(self, x):\n",
    "        D = self.D\n",
    "        h = F.relu(self.conv[0](x))\n",
    "        #!COMPLETE to apply REU activation function to each neuron\n",
    "        y = self.conv[D+1](h) + x\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `DnCNN`is no longer abstract as it implements all of the methods of its ancestors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package `nntools ` introduces another mechanism\n",
    "for running learning experiments.\n",
    "An important aspect when running such an experiment\n",
    "is to regularly create checkpoints or backups\n",
    "of the current model, optimization state and statistics\n",
    "(training loss, validation loss, accuracy, etc).\n",
    "In case of an unexpected error, you need\n",
    "to be able to restart the computation from where it stopped and you do not want to rerun everything\n",
    "from scratch. Typical reasons for your learning to stop are\n",
    "server disconnection/timeout, out of memory errors, CUDA runtime errors, quota exceeded error, etc.\n",
    "\n",
    "The computation of statistics will be delegated to the class\n",
    "`StatsManager `, that provides functionalities to accumulate statistics\n",
    "from different mini batches and then aggregate/summarize the information\n",
    "at the end of each epoch.\n",
    "Read and interpret the code of `StatsManager `.\n",
    "This class is not abstract since it implements all of its methods.\n",
    "We could use an instance of this class to monitor the learning\n",
    "for our classification problem. But this class is too general and then does\n",
    "not compute classification accuracy. Even though the class is not abstract,\n",
    "we can still create a subclass by inheritance and redefine some\n",
    "of its methods, this is called overloading.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A very classical (but controversial) way to compare the quality of restoration\n",
    "  techniques is to use the PSNR\n",
    "  (Peak Signal-to-Noise-Ratio)\n",
    "  defined for images ranging in $[-1, 1]$ as\n",
    "  \\begin{align}\n",
    "    \\text{PSNR} =\n",
    "    10 \\log_{10} \\frac{4 n}{\\|y - d\\|_2^2}\n",
    "  \\end{align}\n",
    "  where $d$ is the desired ideal image, $y$ the estimate obtained from $x$ and\n",
    "  $n$ the number of elements in the tensor.\n",
    "  The PSNR measures in decibels (dB) the quality of the restoration: the higher the better.\n",
    "  \n",
    "\n",
    "### Question 4\n",
    "Create a new subclass\n",
    "`DenoisingStatsManager` that inherits from\n",
    "`StatsManager` and overload each method\n",
    "  by completing the following code.\n",
    "This subclass must compute and average PSNR between mini-batches\n",
    "  (instead of accuracy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingStatsManager(nt.StatsManager):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DenoisingStatsManager, self).__init__()\n",
    "\n",
    "    def init(self):\n",
    "        super(DenoisingStatsManager, self).init()\n",
    "        self.running_psnr =  #!COMPLETE \n",
    "\n",
    "    def accumulate(self, loss, x, y, d):\n",
    "        super(DenoisingStatsManager, self).accumulate(loss, x, y, d)\n",
    "        self.running_psnr += ?  #!COMPLETE \n",
    "    \n",
    "    def summarize(self):\n",
    "        loss = super(DenoisingStatsManager, self).summarize()\n",
    "        psnr = self.running_psnr / self.number_update  \n",
    "        return {'loss': loss, 'psnr': psnr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Experiments will be carried out by the class `Experiment` which\n",
    "is defined with respect to 6 inputs\n",
    "* a given network,\n",
    "    * a given optimizer,\n",
    "    * a given training set,\n",
    "* a given validation set,\n",
    "    * a given mini batch size,\n",
    "    * a given statistic manager.\n",
    "\n",
    "Once instantiated, the experiment can be run for $n$ epochs on the training\n",
    "set by using the method `run`. The statistics\n",
    "at each iteration are stored as a list in the attribute `history`.\n",
    "\n",
    "* An experiment can be evaluated on the validation set by the method \\texttt{evaluate}.\n",
    "    Read the code of that method and\n",
    "    note that first `self.net` is set to `eval` mode.\n",
    "    Read the documentation\n",
    "    \\url{https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval} and\n",
    "    explain why we use this.\n",
    "* The `Experiment` class creates a checkpoint at each epoch and automatically restarts\n",
    "  from the last available checkpoint.\n",
    "  The checkpoint will be saved into (or loaded from) the directory specified by\n",
    "  the optional argument _output\\_dir_ of the constructor.\n",
    "  If not specified, a new directory with an arbitrary name is created.\n",
    "  Take time to read and interpret carefully the code of `Experiment`\n",
    "  and run the following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 4\n",
    "D = 6\n",
    "lr = 1e-3\n",
    "dncnn = DnCNN(D, apply_init=True)\n",
    "dncnn = dncnn.to(device)\n",
    "adam = torch.optim.Adam(dncnn.parameters(), lr=lr)\n",
    "stats_manager = DenoisingStatsManager()\n",
    "exp1 = nt.Experiment(dncnn, train_set, val_set, adam, stats_manager, batch_size=B,\n",
    "                     output_dir=\"denoising1\", perform_validation_during_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Check that a directory `denoising1` has been created and inspect its content.\n",
    "  Explain the file _config.txt_.\n",
    "  What does the file _checkpoint.pth.tar_ correspond to? Base your answer on Pytorch documentation, `torch.save() ` and `nntools.py`.\n",
    "\n",
    "Note: Do not try to open checkpoint.pth.tar file in a text editor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Run the experiment for 20 epochs by executing the following code. Your function  should display at every $visu\\_rate$ epochs\n",
    "something similar to the results given here after.\n",
    " If it does not, interrupt it, \n",
    "check your code, delete the `output_dir`,\n",
    "and start again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(exp, fig, axes, noisy, visu_rate=3):\n",
    "    if exp.epoch % visu_rate != 0:\n",
    "        return\n",
    "    with torch.no_grad():\n",
    "        denoised = exp.net(noisy[np.newaxis].to(exp.net.device))[0]\n",
    "    axes[0][0].clear()\n",
    "    axes[0][1].clear()\n",
    "    axes[1][0].clear()\n",
    "    axes[1][1].clear()\n",
    "    myimshow(noisy, ax=axes[0][0])\n",
    "    axes[0][0].set_title('Noisy image')\n",
    "    myimshow(denoised, ax=axes[0][1])\n",
    "    axes[0][1].set_title('Denoised image')    \n",
    "    axes[1][0].plot([exp.history[k][0]['loss'] for k in range(exp.epoch)], label=\"traininng loss\")\n",
    "    axes[1][1].plot([exp.history[k][0]['psnr'] for k in range(exp.epoch)], label=\"traininng psnr\")\n",
    "    axes[1][0].plot([exp.history[k][1]['loss'] for k in range(exp.epoch)], label=\"evaluation loss\")\n",
    "    axes[1][1].plot([exp.history[k][1]['psnr'] for k in range(exp.epoch)], label=\"evaluation psnr\")\n",
    "    axes[1][0].legend()\n",
    "    axes[1][0].set_xlabel(\"Epoch\")\n",
    "    axes[1][0].set_ylabel(\"Loss\")        \n",
    "    axes[1][1].legend()\n",
    "    axes[1][1].set_xlabel(\"Epoch\")\n",
    "    axes[1][1].set_ylabel(\"PSNR\")    \n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7,6))\n",
    "exp1.run(num_epochs=30, plot=lambda exp: plot(exp, fig=fig, axes=axes, noisy=test_set[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Compare the noisy, clean and denoised results on a few images of the testing set. Evaluate the visual quality of your result.\n",
    "Do you see any artifacts or loss of information?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = td.DataLoader(test_set, batch_size=B, shuffle=True,\n",
    "                            drop_last=True, pin_memory=True)\n",
    "_, sample = next(enumerate(test_loader))\n",
    "noisy, clean = sample\n",
    "clean = clean.to(device)\n",
    "noisy = noisy.to(device)\n",
    "with torch.no_grad():\n",
    "    denoised = dncnn(noisy)\n",
    "for k in range(clean.shape[0]):\n",
    "    fig, axis = plt.subplots(ncols=3, figsize=(7,2), sharex='all', sharey='all')\n",
    "    myimshow(noisy[k], ax=axis[0])\n",
    "    axis[0].set_title('Noisy image')\n",
    "    myimshow(denoised[k], ax=axis[1])\n",
    "    axis[1].set_title('Denoised image')\n",
    "    myimshow(clean[k], ax=axis[2])\n",
    "    axis[2].set_title('Clean image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkorchid\"><b># answer here</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "What is the number of parameters of DnCNN(D)? What is the receptive field of DnCNN(D), i.e,how many input pixels do influence an output pixel?\n",
    "\n",
    "Denoising literature claims that for reducing Gaussian noise of standard\n",
    "  deviation $\\sigma=30$ efficiently, a pixel should be influenced by\n",
    "  at least $33 \\times 33$ pixels. How large $D$ (how deep) should\n",
    "  DnCNN be to satisfy this constraint? What would be the implication on\n",
    "  the number of parameters and the computation time?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkorchid\"><b># answer here</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 U-net like CNNs\n",
    "Pooling layers allows us to increase the receptive field\n",
    "without making the network deeper and slower. But\n",
    "pooling layers lose spatial resolution.\n",
    "In order to retrieve the spatial dimension we will have to use unpooling.\n",
    "Our architecture will resemble the so-called U-net architecture\n",
    "(that was originally introduced for image segmentation).\n",
    "Our network will consist of a contracting path and an expansive path,\n",
    "which gives it the U-shaped architecture. The contracting path is\n",
    "a typical convolutional network that consists of repeated application\n",
    "of convolutions, ReLU and max pooling operation. During the contraction,\n",
    "the spatial information is reduced.\n",
    "The expansive pathway reconstructs spatial information through a sequence of\n",
    "unpooling and convolutions (note that if we were using strided convolutions, we\n",
    "would have to use transpose convolutions), and combined\n",
    "high-resolution features from the contracting path.\n",
    "In the original U-net, features were combined by concatenating the channels\n",
    "of the tensors, but here we will consider their sum divided by $\\sqrt{2}$\n",
    "(this is to preserve the range of feature variations).\n",
    "The architecture is summarized in the following scheme. \n",
    "\n",
    "\n",
    "\n",
    "![DnCNN](./udncnn.jpg)\n",
    "\n",
    "### Question 9\n",
    "Complete the following code to implement this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UDnCNN(NNRegression):\n",
    "\n",
    "    def __init__(self, D, C=64):\n",
    "        super(UDnCNN, self).__init__()\n",
    "        self.D = D\n",
    "        self.conv = nn.ModuleList()\n",
    "        #!COMPLETE\n",
    "\n",
    "    def forward(self, x):\n",
    "        D = self.D\n",
    "        \n",
    "        h = [None] * int(D + 1)\n",
    "        i = [None] * int(D/2-1)\n",
    "        s = [None] * int(D/2-1)\n",
    "        \n",
    "        h[0] = F.relu(self.conv[0](x))\n",
    "        \n",
    "        for k in range(int(D/2)-1):\n",
    "            h[k+1] = F.relu(?)  #!COMPLETE\n",
    "            s[k] = h[k+1].shape #needed for unpool layers\n",
    "            h[k+1], i[k] = F.max_pool2d(h[k+1], (2,2), return_indices=True)\n",
    "        \n",
    "        k = int(D/2) - 1\n",
    "        h[k+1] = F.relu(?) #!COMPLETE\n",
    "        k = int(D/2)\n",
    "        \n",
    "        h[k+1] = F.relu(?) #!COMPLETE\n",
    "        h[k+1] = (h[k+1] + h[k-1]) / np.sqrt(2)\n",
    "        \n",
    "        for k in range(int(D/2)+1, D):\n",
    "            l = D - k - 1\n",
    "            h[k] = F.max_unpool2d(h[k], i[l], (2,2), output_size=s[l])\n",
    "            h[k+1] = F.relu(?) #!COMPLETE\n",
    "            h[k+1] = (h[k+1] + h[l]) / np.sqrt(2)\n",
    "        y = self.conv[D + 1](h[D]) + x\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "Test it this architecture and analyze the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkorchid\"><b># answer here</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "What is its number of parameters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkorchid\"><b># answer here</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_Note : Though pooling layers\n",
    "increase the receptive field, they lose information about exact locations.\n",
    "This is desired for classification, but for denoising this decreases performance.\n",
    "An alternative to pooling is to use dilated convolutions\n",
    "(sometimes refer to the {\\it \\`a trous} algorithm, meaning {\\it with holes}).\n",
    "Instead of increasing the receptive field by reducing the feature spatial\n",
    "dimensions by a factor 2 after each convolution, the filters are dilated\n",
    "by a factor 2. _"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
